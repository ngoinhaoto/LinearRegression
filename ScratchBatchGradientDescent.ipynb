{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex3: Use Batch Gradient Descent to find Theta(W), also provided somewhat similar result(theta=[31.98, 1.84] compared to theta = [34.04, 1.89] by using Linear Regression), but BGD can be used for bigger and more complex data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random x và y\n",
    "X = np.random.rand(100, 1)\n",
    "y = 32 + 1.8 * X + .01*np.random.rand(100,1)\n",
    "N = X.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = np.ones((X.shape[0], 1))\n",
    "X = np.concatenate((one, X), axis = 1) #thêm 1 vào X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#đạo hàm của hàm mất mát: 1/N * X.T * (X.W - y), W là theta hoặc là gọi là waste\n",
    "def gradient(theta):\n",
    "    return 1/N * X.T.dot(X.dot(theta) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(theta_init, learning_rate): #learning rate còn được gọi là eta\n",
    "    theta = theta_init #theta(t+1) = theta(t) - learning_rate * f'(theta(t))\n",
    "                        #f'(theta(t)) = gradient(theta(t)): đạo hàm\n",
    "    for it in range(100): #chạy 100 lần\n",
    "        theta_new = theta - learning_rate * gradient(theta)\n",
    "\n",
    "        #kiểm tra xem thử nếu gradient(theta_new) đủ nhỏ, trong trường hợp này ta so matrix của gradient(theta_new) với 0.0001 hoặc là 1e-3\n",
    "        #bằng cách là dùng hàm np.linalg.norm(), hàm này tính khoảng cách trong ma trận\n",
    "         \n",
    "        if np.linalg.norm(gradient(theta_new))/len(theta_new) < 1e-3:\n",
    "            break\n",
    "\n",
    "        theta = theta_new\n",
    "        \n",
    "    return (theta, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta =  [[31.98612763  1.83443681]]\n",
      "iteration =  100\n"
     ]
    }
   ],
   "source": [
    "(theta, iteration) = batch_gradient_descent(theta_init=np.array([[12], [12]]), learning_rate=1)\n",
    "print(\"theta = \", theta.T)\n",
    "print(\"iteration = \", (iteration + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chốt lại là BGD có thể dùng cho bài toán tìm độ C và F và cho ra kết quả khá tương tự với Linear Regression\n",
    "#dù BGD có thể dùng cho lựong data lớn và phức tạp hơn so với Linear Regressions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd2f65b880418e582f40063e7947e1995392960861f5ac048513f3e501a83530"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
